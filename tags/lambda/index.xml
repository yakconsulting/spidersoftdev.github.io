<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Lambda on SpiderSoft</title><link>https://www.spidersoft.com.au/tags/lambda/</link><description>Recent content in Lambda on SpiderSoft</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 27 Mar 2019 08:43:27 +0000</lastBuildDate><atom:link href="https://www.spidersoft.com.au/tags/lambda/index.xml" rel="self" type="application/rss+xml"/><item><title>Automated email parser</title><link>https://www.spidersoft.com.au/2019/automated-email-parser/</link><pubDate>Wed, 27 Mar 2019 08:43:27 +0000</pubDate><guid>https://www.spidersoft.com.au/2019/automated-email-parser/</guid><description>&lt;p&gt;It&amp;rsquo;s a simple mechanic to decompose emails into valuable parts, like some markup (to push emails directly into internal systems), create file attachments and extract inline images.&lt;/p&gt;
&lt;p&gt;Flow is pretty simple, but we have a couple of components.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;We need something to “receive” emails. The easiest way is to use Amazon SES or mailgun or… something else. There are a couple of SASS solutions for that.&lt;/li&gt;
&lt;li&gt;Next step is to be notified when the email arrives, so we don’t have overhead with checking email every couple of minutes&lt;/li&gt;
&lt;li&gt;We have to “decompose” – decode email from it’s raw format to text, and attachments. We can achieve that using couple of existing libraries, but you get the idea&lt;/li&gt;
&lt;li&gt;We have to save all data and expose it to public&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So we know what to do and roughly how to do the whole process. Points 1 and 2 are pretty straightforward for anyone who uses AWS and their services.&lt;/p&gt;</description></item></channel></rss>